{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- # Before you use this template\n",
        "\n",
        "This template is just a recommended template for project Report. It only considers the general type of research in our paper pool. Feel free to edit it to better fit your project. You will iteratively update the same notebook submission for your draft and the final submission. Please check the project rubriks to get a sense of what is expected in the template.\n",
        "\n",
        "---\n",
        "\n",
        "# FAQ and Attentions\n",
        "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
        "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
        "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
        "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
        "must be within 8 min, otherwise, you may get penalty on the grade.\n",
        "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
        "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
        "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
        "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
        "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
        "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary. -->"
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "* **Github: https://github.com/xiaorandu/dl4h_project**\n",
        "*   **Background of the problem**\n",
        "  * **type of problem:** Artificial intelligence (AI) is being used to help aid drug discovery; however, many of these processes focus on the studies of chemical structures and largely ignoring the plethora of information found in text-based instructions. This limitation hinders the advancement of textual descriptions for drug design, molecule editing, and predicting complex biological activities.\n",
        "\n",
        "  * **importance/meaning of solving the problem:** Solving this problem will help enable faster iterations of drug discovery, such as re-purposing and multi-objective lead optimization.\n",
        "\n",
        "  * **the difficulty of the problem:** This problem contains many difficult aspects including the zero shot learning tasks (which are especially difficult in the context of bio chemistry) and understanding natural language. Data insufficiency (PubChemSTM consists of 250,000 molecules and 281,000 structure-text pairs vs. 400 million in the vision-language domain used by peers from other domains) is another limitation, and the expressiveness of chemical structure models is also a bottleneck of this work.\n",
        "\n",
        "  * **the state of the art methods and effectiveness:** A multi modal model was designed that incorporates both molecular structural information and textual knowledge. A multi modal model, MoleculeSTM, which consists of two brances, the chemical structure branch (to handle molecules' internal structure)  and textual description branch (to handle external domain knowledge) was designed. Such design enables the model to be integrated with existing models trained on each seperately , i.e., molecular structural models and scientific language models. A large multi-modal structure-text dataset was created to align the two branhes of MoleculeSTM. Two challenging downstream tasks were desinged, the structure retrieval task and text based molecule editing task and petrained MoleculeSTM was applied on them in a zero-shot manner. By studing these tasks two main attributes of MoleculeSTM were summaried, open vocabulary and composibilty. Open vocabulary means the model can support exploring a wide range of biochemical concepts with unbound vocabulary. Compositionality means complex concepts can be expressed by decomposing it into several simpler concepts. Results had shown the effectiveness of MoleculeSTM can reach the best performance on six zero-shot retrival tasks, which is up to 50% higher accuracy and twenty zero-shot text-based editing tasks, which is up to 40% higher hit ratio when comparing with the stsate-of-the-art methods. Additionally, MoleculeSTM was able to detect critical structure inferred by text descriptions for molecular editing tasks.\n",
        "\n",
        "*   **Paper explanation**\n",
        "  * **what did the paper propose:** The paper introduced MoleculeSTM, a model that integrates chemical structures of molecules with their textual descriptions using a contrastive learning approach. The model aims to perform tasks such as structure-text retrieval and molecule editing based on text instructions in a zero-shot setting. It utilizes a vast, multi-modal dataset, PubChemSTM, containing over 280,000 chemical structure-text pairs.\n",
        "\n",
        "  * **innovations of the method:** MoleculeSTM uniquely combines chemical structural data with textual information, enhancing the model's understanding and generalization capabilities across various biochemical contexts. It demonstrates significant effectiveness in zero-shot scenarios, where the model performs tasks without having been explicitly trained on them. The model supports open-ended vocabularies and can decompose complex instructions into simpler concepts, making it versatile in handling diverse and novel scientific queries.\n",
        "\n",
        "  * **how well the proposed method work (in its own metrics):** MoleculeSTM significantly outperformed existing methods in zero-shot retrieval and text-based molecule editing tasks. It achieved up to 50% higher accuracy in retrieval tasks and up to 40% higher hit ratios in editing tasks compared to state-of-the-art methods. This indicates a robust ability to generalize and effectively apply learned knowledge to new and unseen data.\n",
        "\n",
        "  * **what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem):** The research incorporated textual descriptions with chemical structures for molecule representation learning.The multi-modal model, MoleculeSTM, consistently showed improved performance when compared to the existing models. MoleculeSTM might accelerate various downstream drug discovery practices, since it was observed that the model can successfully modify molecule substructures to gain desired properties and also retrieve novel drug-target relations. This paper is important as it was able to illustrate the effictiveness of incorporating textual descriptions in addition to chemical structures for molecule representation learning. It did have two limitations,data insufficiency and expressiveness of the chemical structure models.\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper we will test and the corresponding experiments you will run.\n",
        "\n",
        "Hypothesis:\n",
        "1. MoleculeSTM achieves state-of-the-art performance in zero-shot structure-text retrieval and molecule editing tasks compared to the existing method.\n",
        "2. Incorporating textual descriptions through contrastive learning will significantly improve the model's performance on zero-shot retrieval and molecule editing tasks.\n",
        "\n",
        "Experiments:\n",
        "Retraining the model on the constructed PubChemSTM dataset, consisting of over 280,000 chemical structure-text pairs, and evaluating it on specified zero-shot tasks: structure-text retrieval and molecule editing.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Environment"
      ],
      "metadata": {
        "id": "4j7hn1WK6WMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python version\n"
      ],
      "metadata": {
        "id": "zLF7R1Kv6r05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "t2WqmBOX64Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python 3.10.12"
      ],
      "metadata": {
        "id": "Lt2nzVvzhZfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies/packages needed"
      ],
      "metadata": {
        "id": "fIHuhq7A6myH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installed packages\n",
        "!pip install rdkit\n",
        "!pip install torch torchvision\n",
        "!pip install requests tqdm matplotlib spacy Levenshtein boto3 deepspeed\n",
        "!pip install ogb==1.2.0\n",
        "!pip install transformers==4.30.2\n",
        "\n",
        "!pip install torch_geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install git+https://github.com/MolecularAI/pysmilesutils.git"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install apex\n",
        "!git clone https://github.com/chao1224/apex.git\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir ./\n",
        "%cd .."
      ],
      "metadata": {
        "id": "syK8SSjkhS2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install metagron\n",
        "!git clone https://github.com/MolecularAI/MolBART.git --branch megatron-molbart-with-zinc\n",
        "%cd MolBART/megatron_molbart/Megatron-LM-v1.1.5-3D_parallelism\n",
        "!pip install .\n",
        "%cd ../../.."
      ],
      "metadata": {
        "id": "7bwItJOQwJXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "<!-- Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset. -->"
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Data download instruction\n",
        "We can use the following python script to download the pretraining dataset and downstream datasets."
      ],
      "metadata": {
        "id": "XzVUQS0CHry0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, snapshot_download\n",
        "api = HfApi()\n",
        "snapshot_download(repo_id=\"chao1224/MoleculeSTM\", repo_type=\"dataset\", local_dir='data')"
      ],
      "metadata": {
        "id": "2qrB1KAwzX5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data folder can be found at [google drive link](https://drive.google.com/drive/u/0/folders/1pCr0WrY-3lbxxy44D68u2cDzmDONVLBD).\n",
        "<br/>The data folder will include:\n",
        "```\n",
        "data\n",
        "├── PubChemSTM_data/\n",
        "│   └── raw\n",
        "│        └── CID2SMILES.csv\n",
        "│        └── CID2name.json\n",
        "│        └── CID2name_raw.json\n",
        "│        └── molecules.sdf\n",
        "│   └── processed/\n",
        "├── pretrained_SciBERT/\n",
        "├── pretrained_MegaMolBART/\n",
        "├── pretrained_KV-PLM/\n",
        "├── pretrained_GraphMVP/\n",
        "├── pretrained_MoleculeSTM_Raw/\n",
        "├── pretrained_MoleculeSTM/\n",
        "├── DrugBank_data/\n",
        "├── ZINC250K_data/\n",
        "├── Editing_data/\n",
        "│   └── single_multi_property_SMILES.txt\n",
        "│   └── neighbor2drug/\n",
        "│   └── ChEMBL_data/\n",
        "└── MoleculeNet_data/\n",
        "```"
      ],
      "metadata": {
        "id": "Oo7bQ8AwzeSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data descriptions with helpful charts and visualizations"
      ],
      "metadata": {
        "id": "hANVl1yo7R42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MoleculeSTM/data/PubChemSTM_data/raw"
      ],
      "metadata": {
        "id": "Ioy_Wg6j77jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The SMILES string views the molecule as a sequence\n",
        "'''\n",
        "import pandas as pd\n",
        "CID2SMILES = 'CID2SMILES.csv'\n",
        "df_CID2SMILES = pd.read_csv(CID2SMILES, usecols=['CID', 'SMILES'])\n",
        "df_CID2SMILES.head()"
      ],
      "metadata": {
        "id": "jlSN1l2H8JEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "index\tCID\tSMILES\n",
        "0\t     1\tCC(=O)OC(CC(=O)[O-])C[N+](C)(C)C\n",
        "1\t     3\tO=C(O)C1=CC=CC(O)C1O\n",
        "2\t     4\tCC(O)CN\n",
        "3\t     5\tNCC(=O)COP(=O)(O)O\n",
        "4\t     6\tO=[N+]([O-])c1ccc(Cl)c([N+](=O)[O-])c1\n",
        "```"
      ],
      "metadata": {
        "id": "Xbw3AlHBgEAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "CID2name_raw = \"CID2name_raw.json\"\n",
        "with open(CID2name_raw, 'r') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "df_CID2name_raw = pd.DataFrame(list(data.items()), columns=['CID', 'Names'])\n",
        "df_CID2name_raw.head()"
      ],
      "metadata": {
        "id": "RSB49QE4NsS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "index\tCID\tNames\n",
        "0\t    180\tAcetone,ACETONE,Acetone\n",
        "1\t    222\tAmmonia,AMMONIA SOLUTIONS (CONTAINING MORE THAN 35% BUT NOT MORE THAN 50% AMMONIA),AMMONIA, ANHYDROUS,AMMONIA, SOLUTION, WITH MORE THAN 10% BUT NOT MORE THAN 35% AMMONIA,Ammonia\n",
        "2\t   5359596\tArsenic,ARSENIC,Arsenic,Arsenic atom,Arsenic Compounds\n",
        "3\t    241\tBenzene,BENZENE,Benzene,Benzene\n",
        "4\t   23973\tCadmium,CADMIUM,Cadmium atom,Cadmium,Cadmium Compounds\n",
        "```"
      ],
      "metadata": {
        "id": "PuBWGhV-gWho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "CID2name = \"CID2name.json\"\n",
        "with open(CID2name, 'r') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "df_CID2name = pd.DataFrame(list(data.items()), columns=['CID', 'Names'])\n",
        "df_CID2name.head()"
      ],
      "metadata": {
        "id": "Im2SnRTR9Umy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "index\tCID\tNames\n",
        "0\t    180\tAcetone,Acetone,Acetone,Acetone,Acetone\n",
        "1\t    222\tAmmonia,Ammonia solutions (containing more than 35% but not more than 50% ammonia),Ammonia, anhydrous,Ammonia, solution, with more than 10% but not more than 35% ammonia,Ammonia,Ammonia,Ammonia,Ammonia\n",
        "2\t   5359596\tArsenic,Arsenic,Arsenic,Arsenic atom,Arsenic, a naturally occurring element,,Arsenic\n",
        "3\t    241\tBenzene,Benzene,Benzene,Benzene,Benzene,Benzene\n",
        "4\t   23973\tCadmium,Cadmium,Cadmium atom,The main sources of cadmium in the air,Cadmium,Cadmium,Cadmium\n",
        "```"
      ],
      "metadata": {
        "id": "hh3sN5gAghSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import PandasTools\n",
        "\n",
        "sdf_file = \"molecules.sdf\"\n",
        "df_molecules = PandasTools.LoadSDF(sdf_file)\n",
        "print(df_molecules.head())"
      ],
      "metadata": {
        "id": "b8rVWwCcCgJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# the output would be like this.\n",
        "  PUBCHEM_COMPOUND_CID PUBCHEM_COMPOUND_CANONICALIZED  \\\n",
        "0             29500027                              1   \n",
        "1             29500038                              1   \n",
        "2             29500039                              1   \n",
        "3             29500070                              1   \n",
        "4             29500073                              1   \n",
        "\n",
        "  PUBCHEM_CACTVS_COMPLEXITY PUBCHEM_CACTVS_HBOND_ACCEPTOR  \\\n",
        "0                       460                             7   \n",
        "1                       480                             6   \n",
        "2                       480                             6   \n",
        "3                       543                             6   \n",
        "4                       451                             6   \n",
        "\n",
        "  PUBCHEM_CACTVS_HBOND_DONOR PUBCHEM_CACTVS_ROTATABLE_BOND  \\\n",
        "0                          1                             4   \n",
        "1                          2                             6   \n",
        "2                          2                             6   \n",
        "3                          1                             4   \n",
        "4                          2                             3   \n",
        "\n",
        "                             PUBCHEM_CACTVS_SUBSKEYS  \\\n",
        "0  AAADccB7oABAAAAAAAAAAAAAAAAAAWLAAAA8QAAAAAAAAA...   \n",
        "1  AAADceB7sABgAAAAAAAAAAAAAAAAAWJAAAAsAAAAAAAAAA...   \n",
        "2  AAADceB7sABgAAAAAAAAAAAAAAAAAWJAAAAsAAAAAAAAAA...   \n",
        "3  AAADceB7oABAAAAAAAAAAAAAAAAAAWLAAAAwYAAAAAAAAA...   \n",
        "4  AAADceB7oABAAAAAAAAAAAAAAAAAAWAAAAA8QAAAAAAAAA...   \n",
        "\n",
        "                          PUBCHEM_IUPAC_OPENEYE_NAME  \\\n",
        "0  N-[4-(2-pyridyl)thiazol-2-yl]-4-(tetrazol-1-yl...   \n",
        "1  (3S)-3-acetamido-N-[4-(2-pyridyl)thiazol-2-yl]...   \n",
        "2  (3R)-3-acetamido-N-[4-(2-pyridyl)thiazol-2-yl]...   \n",
        "3  4-(tetrazol-1-yl)-N-[4-(2,4,5-trimethylphenyl)...   \n",
        "4  3-amino-N-[4-(2,4,5-trimethylphenyl)thiazol-2-...   \n",
        "\n",
        "                              PUBCHEM_IUPAC_CAS_NAME  \\\n",
        "0  N-[4-(2-pyridinyl)-2-thiazolyl]-4-(1-tetrazoly...   \n",
        "1  (3S)-3-acetamido-N-[4-(2-pyridinyl)-2-thiazoly...   \n",
        "2  (3R)-3-acetamido-N-[4-(2-pyridinyl)-2-thiazoly...   \n",
        "3  4-(1-tetrazolyl)-N-[4-(2,4,5-trimethylphenyl)-...   \n",
        "4  3-amino-N-[4-(2,4,5-trimethylphenyl)-2-thiazol...   \n",
        "\n",
        "                           PUBCHEM_IUPAC_NAME_MARKUP  ...  \\\n",
        "0  <I>N</I>-(4-pyridin-2-yl-1,3-thiazol-2-yl)-4-(...  ...   \n",
        "1  (3<I>S</I>)-3-acetamido-<I>N</I>-(4-pyridin-2-...  ...   \n",
        "2  (3<I>R</I>)-3-acetamido-<I>N</I>-(4-pyridin-2-...  ...   \n",
        "3  4-(tetrazol-1-yl)-<I>N</I>-[4-(2,4,5-trimethyl...  ...   \n",
        "4  3-amino-<I>N</I>-[4-(2,4,5-trimethylphenyl)-1,...  ...   \n",
        "\n",
        "  PUBCHEM_BOND_UDEF_STEREO_COUNT PUBCHEM_ISOTOPIC_ATOM_COUNT  \\\n",
        "0                              0                           0   \n",
        "1                              0                           0   \n",
        "2                              0                           0   \n",
        "3                              0                           0   \n",
        "4                              0                           0   \n",
        "\n",
        "  PUBCHEM_COMPONENT_COUNT PUBCHEM_CACTVS_TAUTO_COUNT PUBCHEM_COORDINATE_TYPE  \\\n",
        "0                       1                         -1               1\\n5\\n255   \n",
        "1                       1                         -1               1\\n5\\n255   \n",
        "2                       1                         -1               1\\n5\\n255   \n",
        "3                       1                         -1               1\\n5\\n255   \n",
        "4                       1                         -1               1\\n5\\n255   \n",
        "\n",
        "                             PUBCHEM_BONDANNOTATIONS        ID  \\\n",
        "0  1  18  8\\n1  20  8\\n10  12  8\\n10  13  8\\n11  ...  29500027   \n",
        "1  1  11  8\\n1  16  8\\n11  13  8\\n13  15  8\\n15  ...  29500038   \n",
        "2  1  11  8\\n1  16  8\\n11  13  8\\n13  15  8\\n15  ...  29500039   \n",
        "3  1  19  8\\n1  20  8\\n10  14  8\\n11  12  8\\n11  ...  29500070   \n",
        "4  1  18  8\\n1  19  8\\n10  11  8\\n10  12  8\\n11  ...  29500073   \n",
        "\n",
        "                                              ROMol PUBCHEM_XLOGP3  \\\n",
        "0  <rdkit.Chem.rdchem.Mol object at 0x7d30b3ca4cf0>            NaN   \n",
        "1  <rdkit.Chem.rdchem.Mol object at 0x7d30b3ca4c80>            NaN   \n",
        "2  <rdkit.Chem.rdchem.Mol object at 0x7d30b3ca5070>            NaN   \n",
        "3  <rdkit.Chem.rdchem.Mol object at 0x7d30b3ca51c0>            NaN   \n",
        "4  <rdkit.Chem.rdchem.Mol object at 0x7d30b3ca5310>            NaN   \n",
        "\n",
        "  PUBCHEM_REFERENCE_STANDARDIZATION  \n",
        "0                               NaN  \n",
        "1                               NaN  \n",
        "2                               NaN  \n",
        "3                               NaN  \n",
        "4                               NaN  \n",
        "```"
      ],
      "metadata": {
        "id": "0b_FWKgCMc8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing code + command"
      ],
      "metadata": {
        "id": "KfSQcMIk7lmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The preprocessing code can be found at preprocessing/PubchemSTM folder."
      ],
      "metadata": {
        "id": "yv49mufsG2mO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "<!-- The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it. -->"
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Citation to the original paper\n",
        "```\n",
        "@article{liu2023moleculestm,\n",
        "    title={Multi-modal molecule structure-text model for text-based retrieval and editing},\n",
        "    author={Liu, Shengchao and Nie, Weili and Wang, Chengpeng and Lu, Jiarui and Qiao, Zhuoran and Liu, Ling and Tang, Jian and Xiao, Chaowei and Anandkumar, Anima},\n",
        "    title={Multi-modal molecule structure--text model for text-based retrieval and editing},\n",
        "    journal={Nature Machine Intelligence},\n",
        "    year={2023},\n",
        "    month={Dec},\n",
        "    day={01},\n",
        "    volume={5},\n",
        "    number={12},\n",
        "    pages={1447-1457},\n",
        "    issn={2522-5839},\n",
        "    doi={10.1038/s42256-023-00759-6},\n",
        "    url={https://doi.org/10.1038/s42256-023-00759-6}\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "DjwtTKdrbw6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Link to the original paper’s repo\n",
        "https://github.com/chao1224/MoleculeSTM"
      ],
      "metadata": {
        "id": "vCpNIGIFcOJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model descriptions\n",
        "Multi-modal molecule structure-text model(MoleculeSTM) combines the chemical structure of molecules and their textual descriptions to enhance the capacities of artificial intelligence in drug discovery. MoleculeSTM utilizes a contrastive learning strategy to jointly learn from over 280,000 chemical structure-text pairs in PubChemSTM. This training approach allows the model to perform zero-shot tasks based on textual instructions, such as molecule structure-text retrieval and molecule editing. MoleculeSTM leverages an open vocabulary and compositionality through natural language, demonstrating state-of-the-art generalization across various benchmarks without the need for labeled examples or fine-tuning."
      ],
      "metadata": {
        "id": "Thfk79jmcd-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation code"
      ],
      "metadata": {
        "id": "tCXoJGaGcjlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Pretraining**"
      ],
      "metadata": {
        "id": "uBnArcEXlol7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1. Chemical structure branch fc**\n",
        "*   Pretraining SMILES\n",
        "*   Pretraining Graph\n",
        "<br/>\n",
        "Notes: We currently focus on pretraining Graph.\n",
        "\n"
      ],
      "metadata": {
        "id": "uHKYhG8VnvBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('MoleculeSTM')"
      ],
      "metadata": {
        "id": "XUH0_6tIy9yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd scripts"
      ],
      "metadata": {
        "id": "WadTAP4T1j5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the molecular graph, we take a pretrained graph isomorphism network15 using GraphMVP pretraining.\n",
        "! python pretrain.py \\\n",
        "    --verbose --batch_size=8 \\\n",
        "    --molecule_type=Graph"
      ],
      "metadata": {
        "id": "t2UrL1ESpkfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1 Downstream: Zero-shot Structure-text Retrieval**"
      ],
      "metadata": {
        "id": "d6VHPwwvlnjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### for DrugBank-Description"
      ],
      "metadata": {
        "id": "Zl3cVcuRCRdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For graphs\n",
        "! python downstream_01_retrieval_Description_Pharmacodynamics.py \\\n",
        "    --task=molecule_description_removed_PubChem \\\n",
        "    --molecule_type=Graph \\\n",
        "    --input_model_dir=../data/demo/demo_checkpoints_Graph"
      ],
      "metadata": {
        "id": "xrPrpbMRojHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### for DrugBank-Pharmacodynamics"
      ],
      "metadata": {
        "id": "Ao_c4g9ja0OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python downstream_01_retrieval_Description_Pharmacodynamics.py \\\n",
        "    --task=molecule_pharmacodynamics_removed_PubChem \\\n",
        "    --molecule_type=Graph \\\n",
        "    --input_model_dir=../data/demo/demo_checkpoints_Graph"
      ],
      "metadata": {
        "id": "Tz2NHqIza4ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### for DrugBank-ATC"
      ],
      "metadata": {
        "id": "f1W3Clc0a6Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python downstream_01_retrieval_ATC.py \\\n",
        "    --molecule_type=Graph \\\n",
        "    --input_model_dir=../data/demo/demo_checkpoints_Graph"
      ],
      "metadata": {
        "id": "Ur9RZBHJa_IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2 Downstream: Zero-shot Text-based Molecule Editing**"
      ],
      "metadata": {
        "id": "JJHi_2OQ86QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For graphs\n",
        "! python downstream_02_molecule_edit_step_01_MoleculeSTM_Space_Alignment.py \\\n",
        "    --MoleculeSTM_molecule_type=Graph \\\n",
        "    --MoleculeSTM_model_dir=../data/demo/demo_checkpoints_Graph\n",
        "\n",
        "\n",
        "! python downstream_02_molecule_edit_step_02_MoleculeSTM_Latent_Optimization.py \\\n",
        "    --MoleculeSTM_molecule_type=Graph \\\n",
        "    --MoleculeSTM_model_dir=../data/demo/demo_checkpoints_Graph \\\n",
        "    --language_edit_model_dir=../data/demo/demo_checkpoints_Graph \\\n",
        "    --input_description_id=101"
      ],
      "metadata": {
        "id": "UvYcCjyL8-jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3 Downstream: Molecular Property Prediction**"
      ],
      "metadata": {
        "id": "hLQYp0R_8-98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For graphs\n",
        "! python downstream_03_property_prediction.py \\\n",
        "    --dataset=bace --molecule_type=Graph"
      ],
      "metadata": {
        "id": "jaZEgkOW9E90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Training"
      ],
      "metadata": {
        "id": "oGsJVOsBer6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computational requirements\n",
        "\n",
        "\n",
        "*   Hardware: Google Colab V100 GPU, RAM 16GB\n",
        "*   Seeds: 42\n",
        "*   Training epochs: 100\n",
        "*   Computing time:\n",
        "\n"
      ],
      "metadata": {
        "id": "R-dnmAqjew13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation code"
      ],
      "metadata": {
        "id": "nOKWSpZiezMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Functions and Setup:"
      ],
      "metadata": {
        "id": "rKQgsVI45Mdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# entire blockfor property prediction Graph\n",
        "def train_classification(model, device, loader, optimizer):\n",
        "    if args.training_mode == \"fine_tuning\":\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    linear_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    if args.verbose:\n",
        "        L = tqdm(loader)\n",
        "    else:\n",
        "        L = loader\n",
        "    for step, batch in enumerate(L):\n",
        "        if args.molecule_type == \"MegaMolBART\":\n",
        "            SMILES_list, y = batch\n",
        "            SMILES_list = list(SMILES_list)\n",
        "            molecule_repr = get_molecule_repr_MoleculeSTM(\n",
        "                SMILES_list, mol2latent=None,\n",
        "                molecule_type=\"MegaMolBART\", MegaMolBART_wrapper=MegaMolBART_wrapper)\n",
        "            pred = linear_model(molecule_repr)\n",
        "            pred = pred.float()\n",
        "            y = y.to(device).float()\n",
        "        else:\n",
        "            batch = batch.to(device)\n",
        "            molecule_repr = get_molecule_repr_MoleculeSTM(\n",
        "                batch, mol2latent=None,\n",
        "                molecule_type=\"Graph\", molecule_model=model)\n",
        "            pred = linear_model(molecule_repr)\n",
        "            pred = pred.float()\n",
        "            y = batch.y.view(pred.shape).to(device).float()\n",
        "\n",
        "        is_valid = y ** 2 > 0\n",
        "        loss_mat = criterion(pred, (y + 1) / 2)\n",
        "        loss_mat = torch.where(\n",
        "            is_valid, loss_mat,\n",
        "            torch.zeros(loss_mat.shape).to(device).to(loss_mat.dtype))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = torch.sum(loss_mat) / torch.sum(is_valid)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.detach().item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_classification(model, device, loader):\n",
        "    model.eval()\n",
        "    linear_model.eval()\n",
        "    y_true, y_scores = [], []\n",
        "\n",
        "    if args.verbose:\n",
        "        L = tqdm(loader)\n",
        "    else:\n",
        "        L = loader\n",
        "    for step, batch in enumerate(L):\n",
        "        if args.molecule_type == \"MegaMolBART\":\n",
        "            SMILES_list, y = batch\n",
        "            SMILES_list = list(SMILES_list)\n",
        "            molecule_repr = get_molecule_repr_MoleculeSTM(\n",
        "                SMILES_list, mol2latent=None,\n",
        "                molecule_type=\"MegaMolBART\", MegaMolBART_wrapper=MegaMolBART_wrapper)\n",
        "            pred = linear_model(molecule_repr)\n",
        "            pred = pred.float()\n",
        "            y = y.to(device).float()\n",
        "        else:\n",
        "            batch = batch.to(device)\n",
        "            molecule_repr = get_molecule_repr_MoleculeSTM(\n",
        "                batch, mol2latent=None,\n",
        "                molecule_type=\"Graph\", molecule_model=model)\n",
        "            pred = linear_model(molecule_repr)\n",
        "            pred = pred.float()\n",
        "            y = batch.y.view(pred.shape).to(device).float()\n",
        "\n",
        "        y_true.append(y)\n",
        "        y_scores.append(pred)\n",
        "\n",
        "    y_true = torch.cat(y_true, dim=0).cpu().numpy()\n",
        "    y_scores = torch.cat(y_scores, dim=0).cpu().numpy()\n",
        "\n",
        "    roc_list = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        # AUC is only defined when there is at least one positive data.\n",
        "        if np.sum(y_true[:, i] == 1) > 0 and np.sum(y_true[:, i] == -1) > 0:\n",
        "            is_valid = y_true[:, i] ** 2 > 0\n",
        "            roc_list.append(roc_auc_score((y_true[is_valid, i] + 1) / 2, y_scores[is_valid, i]))\n",
        "        else:\n",
        "            print(\"{} is invalid\".format(i))\n",
        "\n",
        "    if len(roc_list) < y_true.shape[1]:\n",
        "        print(len(roc_list))\n",
        "        print(\"Some target is missing!\")\n",
        "        print(\"Missing ratio: %f\" %(1 - float(len(roc_list)) / y_true.shape[1]))\n",
        "\n",
        "    return sum(roc_list) / len(roc_list), 0, y_true, y_scores\n",
        "\n",
        "# setup for optimizer\n",
        "if args.training_mode == \"fine_tuning\":\n",
        "    model_param_group = [\n",
        "        {\"params\": model.parameters()},\n",
        "        {\"params\": linear_model.parameters(), 'lr': args.lr * args.lr_scale}\n",
        "    ]\n",
        "else:\n",
        "    model_param_group = [\n",
        "        {\"params\": linear_model.parameters(), 'lr': args.lr * args.lr_scale}\n",
        "    ]\n",
        "optimizer = optim.Adam(model_param_group, lr=args.lr, weight_decay=args.weight_decay)"
      ],
      "metadata": {
        "id": "cXhs1ktd5KAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform Training"
      ],
      "metadata": {
        "id": "MGFIjB9t5TYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for property prediction Graph\n",
        "\n",
        "train_func = train_classification\n",
        "eval_func = eval_classification\n",
        "\n",
        "train_roc_list, val_roc_list, test_roc_list = [], [], []\n",
        "train_acc_list, val_acc_list, test_acc_list = [], [], []\n",
        "best_val_roc, best_val_idx = -1, 0\n",
        "criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    loss_acc = train_func(model, device, train_loader, optimizer)\n",
        "    print(\"Epoch: {}\\nLoss: {}\".format(epoch, loss_acc))\n",
        "\n",
        "    if args.eval_train:\n",
        "        train_roc, train_acc, train_target, train_pred = eval_func(model, device, train_loader)\n",
        "    else:\n",
        "        train_roc = train_acc = 0\n",
        "    val_roc, val_acc, val_target, val_pred = eval_func(model, device, val_loader)\n",
        "    test_roc, test_acc, test_target, test_pred = eval_func(model, device, test_loader)\n",
        "\n",
        "    train_roc_list.append(train_roc)\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_roc_list.append(val_roc)\n",
        "    val_acc_list.append(val_acc)\n",
        "    test_roc_list.append(test_roc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(\"train: {:.6f}\\tval: {:.6f}\\ttest: {:.6f}\".format(train_roc, val_roc, test_roc))\n",
        "    print()\n",
        "\n",
        "print(\"best train: {:.6f}\\tval: {:.6f}\\ttest: {:.6f}\".format(train_roc_list[best_val_idx], val_roc_list[best_val_idx], test_roc_list[best_val_idx]))"
      ],
      "metadata": {
        "id": "nCG4GtVHe1ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Evaluation"
      ],
      "metadata": {
        "id": "D61YLwnIfgJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric descriptions"
      ],
      "metadata": {
        "id": "ZS7jMVtNfjWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This evaluation uses several different metrics:\n",
        "\n",
        "\n",
        "*   Contrastive loss - measuring the the performance of the model in correctly identifying true matches from a set of possible matches\n",
        "*   Accuracy - determines the proportion of correctly labeled predictive matches\n",
        "*   Confidence Scores - determines a measure of confidence for each prediction\n",
        "\n",
        "\n",
        "Additionally, the code uses a variety of negative samples to help measure the model's resistence to varying conditions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2D0aAK0l9202"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation code"
      ],
      "metadata": {
        "id": "Ts2-ejAyfn1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Support Functions and Setup"
      ],
      "metadata": {
        "id": "F1Gj_Wp88r65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from demo downstream retrieval Graph\n",
        "def cycle_index(num, shift):\n",
        "    arr = torch.arange(num) + shift\n",
        "    arr[-shift:] = torch.arange(shift)\n",
        "    return arr\n",
        "\n",
        "\n",
        "def do_CL_eval(X, Y, neg_Y, args):\n",
        "    X = F.normalize(X, dim=-1)\n",
        "    X = X.unsqueeze(1) # B, 1, d\n",
        "\n",
        "    Y = Y.unsqueeze(0)\n",
        "    Y = torch.cat([Y, neg_Y], dim=0) # T, B, d\n",
        "    Y = Y.transpose(0, 1)  # B, T, d\n",
        "    Y = F.normalize(Y, dim=-1)\n",
        "\n",
        "    logits = torch.bmm(X, Y.transpose(1, 2)).squeeze()  # B*T\n",
        "    B = X.size()[0]\n",
        "    labels = torch.zeros(B).long().to(logits.device)  # B*1\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    CL_loss = criterion(logits, labels)\n",
        "    pred = logits.argmax(dim=1, keepdim=False)\n",
        "    confidence = logits\n",
        "    CL_conf = confidence.max(dim=1)[0]\n",
        "    CL_conf = CL_conf.cpu().numpy()\n",
        "\n",
        "    CL_acc = pred.eq(labels).sum().detach().cpu().item() * 1. / B\n",
        "    return CL_loss, CL_conf, CL_acc\n",
        "\n",
        "\n",
        "def get_text_repr(text):\n",
        "    text_tokens_ids, text_masks = prepare_text_tokens(\n",
        "        device=device, description=text, tokenizer=text_tokenizer, max_seq_len=args.max_seq_len)\n",
        "    text_output = text_model(input_ids=text_tokens_ids, attention_mask=text_masks)\n",
        "    text_repr = text_output[\"pooler_output\"]\n",
        "    text_repr = text2latent(text_repr)\n",
        "    return text_repr\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(dataloader):\n",
        "    text_model.eval()\n",
        "    molecule_model.eval()\n",
        "    text2latent.eval()\n",
        "    mol2latent.eval()\n",
        "\n",
        "    accum_acc_list = [0 for _ in args.T_list]\n",
        "    if args.verbose:\n",
        "        L = tqdm(dataloader)\n",
        "    else:\n",
        "        L = dataloader\n",
        "    for batch in L:\n",
        "        text = batch[0]\n",
        "        molecule_data = batch[1]\n",
        "        neg_text = batch[2]\n",
        "        neg_molecule_data = batch[3]\n",
        "\n",
        "        text_repr = get_text_repr(text)\n",
        "\n",
        "        molecule_data = molecule_data.to(device)\n",
        "        molecule_repr = get_molecule_repr_MoleculeSTM(\n",
        "            molecule_data, mol2latent=mol2latent,\n",
        "            molecule_type=\"Graph\", molecule_model=molecule_model)\n",
        "\n",
        "        if test_mode == \"given_text\":\n",
        "            neg_molecule_repr = [\n",
        "                get_molecule_repr_MoleculeSTM(\n",
        "                    neg_molecule_data[idx].to(device), mol2latent=mol2latent,\n",
        "                    molecule_type=\"Graph\", molecule_model=molecule_model) for idx in range(T_max)\n",
        "            ]\n",
        "            neg_molecule_repr = torch.stack(neg_molecule_repr)\n",
        "            for T_idx, T in enumerate(args.T_list):\n",
        "                _, _, acc = do_CL_eval(text_repr, molecule_repr, neg_molecule_repr[:T-1], args)\n",
        "                accum_acc_list[T_idx] += acc\n",
        "        elif test_mode == \"given_molecule\":\n",
        "            neg_text_repr = [get_text_repr(neg_text[idx]) for idx in range(T_max)]\n",
        "            neg_text_repr = torch.stack(neg_text_repr)\n",
        "            for T_idx, T in enumerate(args.T_list):\n",
        "                _, _, acc = do_CL_eval(molecule_repr, text_repr, neg_text_repr[:T-1], args)\n",
        "                accum_acc_list[T_idx] += acc\n",
        "        else:\n",
        "            raise Exception\n",
        "\n",
        "    accum_acc_list = np.array(accum_acc_list)\n",
        "    accum_acc_list /= len(dataloader)\n",
        "    return accum_acc_list"
      ],
      "metadata": {
        "id": "5ZFsNDA6fqP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eval"
      ],
      "metadata": {
        "id": "Y8LWvzss9KX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from demo downstream retrieval Graph\n",
        "text_model = text_model.to(device)\n",
        "molecule_model = molecule_model.to(device)\n",
        "text2latent = text2latent.to(device)\n",
        "mol2latent = mol2latent.to(device)\n",
        "\n",
        "T_max = max(args.T_list) - 1\n",
        "\n",
        "initial_test_acc_list = []\n",
        "test_mode = args.test_mode\n",
        "dataset_folder = os.path.join(args.dataspace_path, \"DrugBank_data\")\n",
        "\n",
        "\n",
        "dataset_class = DrugBank_Datasets_Graph_retrieval\n",
        "dataloader_class = pyg_DataLoader\n",
        "processed_dir_prefix = args.task\n",
        "\n",
        "if args.task == \"molecule_description\":\n",
        "    template = \"SMILES_description_{}.txt\"\n",
        "elif args.task == \"molecule_description_removed_PubChem\":\n",
        "    template = \"SMILES_description_removed_from_PubChem_{}.txt\"\n",
        "elif args.task == \"molecule_description_Raw\":\n",
        "    template = \"SMILES_description_{}_Raw.txt\"\n",
        "elif args.task == \"molecule_description_removed_PubChem_Raw\":\n",
        "    template = \"SMILES_description_removed_from_PubChem_{}_Raw.txt\"\n",
        "elif args.task == \"molecule_pharmacodynamics\":\n",
        "    template = \"SMILES_pharmacodynamics_{}.txt\"\n",
        "elif args.task == \"molecule_pharmacodynamics_removed_PubChem\":\n",
        "    template = \"SMILES_pharmacodynamics_removed_from_PubChem_{}.txt\"\n",
        "elif args.task == \"molecule_pharmacodynamics_Raw\":\n",
        "    template = \"SMILES_pharmacodynamics_{}_Raw.txt\"\n",
        "elif args.task == \"molecule_pharmacodynamics_removed_PubChem_Raw\":\n",
        "    template = \"SMILES_pharmacodynamics_removed_from_PubChem_{}_Raw.txt\"\n",
        "\n",
        "full_dataset = dataset_class(dataset_folder, 'full', neg_sample_size=T_max, processed_dir_prefix=processed_dir_prefix, template=template)\n",
        "full_dataloader = dataloader_class(full_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers) # The program will get blcoked with none-zero num_workers\n",
        "\n",
        "initial_test_acc_list = eval_epoch(full_dataloader)"
      ],
      "metadata": {
        "id": "pI4qY8gi9I1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results, Analyses and Plans"
      ],
      "metadata": {
        "id": "zMHv_2C5f6wV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plans\n",
        "*   Resolve setup issues when running the code.\n",
        "<br>Notes: (1) Due to multiple out-of-date and version-conflicted packages in the environment setup, the team has not resolved all the setup issues after lots of attempts on different machines. As a result, the code cannot be fully run for now, and implementing the model training is currently not possible. (2) The team is currently working hard to resolve the environment setup issues and fix bugs in the relevant code, and aiming to make the code executable as soon as possible.\n",
        "\n",
        "*   Complete model training.\n",
        "*   Evaluate the training results and summarize them.\n",
        "*   Document the learning journey in the discussion section.\n",
        "*   Create a video presentation of our work.\n"
      ],
      "metadata": {
        "id": "nuJ1ZNB7f8ZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- ## Model comparison\n",
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper-->"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- # Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        " -->\n",
        "\n",
        "\n",
        ">\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- # References\n",
        "\n",
        "1. Liu, S., Nie, W., Wang, C. et al. Multi-modal molecule structure–text model for\n",
        "text-based retrieval and editing. Nat Mach Intell 5, 1447–1457 (2023).\n",
        "https://doi.org/10.1038/s42256-023-00759-6 -->\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}